## 외부에서 데이터 가져오기 / 결과 저장하는 경우 해당 위치에 지정
external_path:
    - load_train_data_path: /nas001/users/ruci.sung/mnist/train/
    - load_inference_data_path: /nas001/users/ruci.sung/mnist/test/
    - save_train_artifacts_path:
    - save_inference_artifacts_path:
 
external_path_permission:
    - s3_private_key_file:

## 실험에 필요한 파라미터를 설정함 
## - 해당 위치에서 삭제되면, code 의 default 로 실행
user_parameters:
    - train_pipeline:
        - step: input  ## 필수git
          args:
            - input_path: train/
              y_column: label # ground truth 파일에 있는 라벨 정답 항목명을 기입해주세요.
              path_column: image_path # ground truth 파일에 있는 이미지 경로 항목명을 기입해주세요.
              data_source_type: batch
              label_names: [0,1,2,3,4,5,6,7,8,9] # 분류하고자 하는 유형명을 기입해주세요. ground truth 파일에 있는 라벨명과 일치해야 합니다.
              prediction_column_prefix: pred
              probability_column_prefix: prob
              set_images: True # 최초 실행 시 이미지를 로컬에 다운로드 받습니다. False로 두면 로컬 파일을 읽어 실행 속도가 빨라집니다.
        - step: train
          args:
            - model_type: mobilenetv1 # mobilenetv1(기본 모델), high_resolution(고해상도 모델)
              input_shape: [28, 28, 1] # 모든 이미지가 같은 형태여야 합니다.
              resize_shape: [224, 224, 3] # high_resolution 모델을 사용하거나 rand_augmentation을 사용하는 경우 3채널을 사용해야 합니다.
              num_classes: 10 # 총 유형 개수를 기입해주세요.
              epochs: 10 # 학습이 잘 되지 않은 경우 증가시켜주세요.
              batch_size: 64 # batch_size가 크면 학습이 빠르게 수행되지만 너무 크면 하드웨어 성능에 따라 실행되지 않을 수 있습니다.
              train_ratio: 0.8
              rand_augmentation: False # Identity, autocontrast, equalize, rotate, solarize, color, posterize, contrast, brightness, sharpness, shearX, shearY, translateX, translateY 중 임의로 2개 선택하여 임의 변환을 수행합니다.
    - inference_pipeline:
        - step: input
          args:
            - input_path: test/ 
              y_column: label  
              data_source_type: batch
              path_column: image_path
              set_images: True
        - step: inference
          args:
            - none:

## asset 의 설치 정보를 기록       
asset_source:
    - train_pipeline:
        - step: input
          source:  ## git / local 지원
            code: http://mod.lge.com/hub/smartdata/ml-framework/alov2-module/input.git
            # code: local
            branch: vision
            requirements:
              - pillow
              - pandas==1.5.3
        - step: train
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/ic.git
            # code: local
            branch: ic_v1.0.1
            requirements:
              - opencv-python
              - tensorflow==2.9.0
              - scikit-optimize
              - focal-loss
              - keras_applications==1.0.8
    - inference_pipeline:
        - step: input
          source:  ## git / local 지원
            # code: http://mod.lge.com/hub/smartdata/ml-framework/alov2-module/input.git
            code: local
            branch: vision
            requirements:
              - pillow
        - step: inference
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/ic.git
            # code: local
            branch: ic_v1.0.1
            requirements:
              - tensorflow==2.9.0
              - opencv-python
              - scikit-optimize
              - focal-loss

 
control:
    ## 1. 패키지 설치 및 asset 존재 여부를 실험 시마다 체크할지, 한번만 할지 결정
    ## 1-2 requirements.txt 및 종속 패키지들 한번만 설치할 지 매번 설치할지도 결정 
    - get_asset_source: once ## once, every
    # TODO 아래 get_external_data 제작하기
    - get_external_data: once ## once, every
    ## 2. 생성된 artifacts 를 backup 할지를 결정 True/False
    - backup_artifacts: True
    ## 3. pipeline 로그를 backup 할지를 결정 True/False
    - backup_log: True
    ## 4. 저장 공간 사이즈를 결정 (단위 MB)
    - backup_size: 1000
 
    ## 5. Asset 사이 데이터 전달 방법으로 memory, file 를 지원
    - interface_mode: memory
